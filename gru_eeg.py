# -*- coding: utf-8 -*-
"""Copy of GRU_EEG.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Nl4K7JeThQddug8zy2NaRMccffDMqOqB
"""

import numpy as np
import pandas as pd
import seaborn as sns
import tensorflow as tf
import matplotlib.pyplot as plt

df = pd.read_csv("/content/EEG.csv")
df.head()

"""Counting the total for each label in the column label

The column named label consists of NEUTRAL, POSITIVE, and NEGATIVE
"""

df['label'].value_counts()

"""
Checking for null values

Checking for missing values"""

df.isnull().sum()

"""
Labelling the label provided with an integer

NEGATIVE will be labelled as 0, NEUTRAL as 1, POSITIVE as 2"""

label_mapping = {'NEGATIVE': 0, 'NEUTRAL': 1, 'POSITIVE': 2}
df['label'] = df['label'].replace(label_mapping)

"""
Defining X and y

X will contain the original data but without the label column, while y will contain only the label column."""

X = df.drop('label', axis=1).copy()
y = df['label'].copy()

"""Splitting The Data of X and y

Split arrays or matrices of X and y into random train and test subsets.
"""

from sklearn.model_selection import train_test_split
import numpy as np

# Use np.random.randint() to generate a random integer for random_state
X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=np.random.randint(0, 4294967295))

"""**GRU Model**"""

!pip install tensorflow

import tensorflow as tf

inputs = tf.keras.Input(shape=(X_train.shape[1],))
# Use tf.keras.layers.Lambda to wrap tf.expand_dims
expand_dims = tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis=2))(inputs)
gru = tf.keras.layers.GRU(256, return_sequences=True)(expand_dims)
flatten = tf.keras.layers.Flatten()(gru)
outputs = tf.keras.layers.Dense(3, activation='softmax')(flatten)
model = tf.keras.Model(inputs=inputs, outputs=outputs)

model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

print(model.summary())

history = model.fit(X_train, y_train, validation_split=0.2,batch_size=32,epochs=50,
    callbacks=[
        tf.keras.callbacks.EarlyStopping(
            monitor='val_loss',
            patience=8,
            restore_best_weights=True
        )
    ]
)

model_acc = model.evaluate(X_test, y_test, verbose=0)[1]
print("Testing  Accuracy: {:.2f}%".format(model_acc * 100))

from sklearn.metrics import confusion_matrix
y_pred = np.array(list(map(lambda x: np.argmax(x), model.predict(X_test))))
cm = confusion_matrix(y_test, y_pred)

print("Confusion Matrix:\n",(cm))

plt.figure(figsize=(4, 4))
sns.heatmap(cm, annot=True, vmin=0, fmt='g', cbar=False, cmap='Blues')
plt.xticks(np.arange(3) + 0.5, label_mapping.keys())
plt.yticks(np.arange(3) + 0.5, label_mapping.keys())
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix")
plt.show()

from sklearn.metrics import classification_report
clr = classification_report(y_test, y_pred, target_names=label_mapping.keys())

print("Classification Report:\n----------------------\n", clr)

model.save('my_model.h5')

!pip install fpdf

model.save('my_model.keras')

import pandas as pd # Make sure pandas is imported

# Assuming your data is in a CSV file named 'your_data.csv'
df = pd.read_csv('EEG.csv')  # Load your data into a DataFrame called 'df'
print(df.columns)  # Now you can access the columns of the DataFrame

!pip install streamlit

import pandas as pd
from sklearn.preprocessing import StandardScaler
import joblib

# Load your dataset (e.g., EEG.csv)
df = pd.read_csv('EEG.csv')

# Select the relevant columns for scaling (numeric columns)
# Adjust this according to the specific columns that need to be scaled in your dataset
columns_to_scale = df.select_dtypes(include=['float64', 'int64']).columns.tolist()

# Create a StandardScaler object
scaler = StandardScaler()

# Fit the scaler on the selected columns
X = df[columns_to_scale]
scaler.fit(X)

# Save the trained scaler to a file (scaler.pkl)
joblib.dump(scaler, 'scaler.pkl')

print("Scaler saved to scaler.pkl")

import numpy as np
import tensorflow as tf

# Custom function used in Lambda (replace with your actual function)
def custom_function(x):
    return tf.reduce_sum(x, axis=1)  # Adjust according to your model's function

# Load the model with custom_objects for Lambda layers
try:
    model = tf.keras.models.load_model('/path/to/your/model.h5', custom_objects={'custom_function': custom_function})
    print("Model loaded successfully.")
except Exception as e:
    print(f"Error loading model: {e}")

# Define the label mapping for prediction
label_mapping = {0: "Negative", 1: "Neutral", 2: "Positive"}

# Input fields expected by the model
input_fields = [
    "mean_0_a", "mean_1_a", "mean_2_a", "mean_3_a", "mean_4_a",
    "mean_d_0_a", "mean_d_1_a", "mean_d_2_a", "mean_d_3_a", "mean_d_4_a",
    "fft_741_b", "fft_742_b", "fft_743_b", "fft_744_b", "fft_745_b",
    "fft_746_b", "fft_747_b", "fft_748_b", "fft_749_b"
]

# Function to gather inputs from the user
def gather_inputs():
    user_inputs = []

    input_mode = input("Would you like to input values one-by-one or all at once (enter 'one' or 'all')? ").strip().lower()

    if input_mode == 'all':
        print("Please enter the following values all in one line, separated by spaces or commas:")
        input_values = input("Enter values: ")

        # Split input by either commas or spaces
        user_inputs = []
        for value in input_values.replace(',', ' ').split():  # Replace commas with spaces and split by spaces
            try:
                num_value = float(value)
                if num_value != 0:
                    user_inputs.append(num_value)
                else:
                    print("Zero is not allowed. Skipping this value.")
            except ValueError:
                print(f"Invalid input: {value}. Please ensure the input is a number.")

    elif input_mode == 'one':
        for field in input_fields:
            while True:
                value = input(f"Enter value for {field}: ")
                try:
                    validated_value = float(value)
                    if validated_value != 0:
                        user_inputs.append(validated_value)
                        break  # Move to the next input if validation is successful
                    else:
                        print("Zero is not allowed. Please enter a non-zero number.")
                except ValueError:
                    print(f"Invalid input: {value}. Please ensure the input is a number.")

    else:
        print("Invalid input mode. Please choose 'one' or 'all'.")

    return user_inputs

# Collect and validate user inputs
user_inputs = gather_inputs()

# Check if the user provided all required values
if len(user_inputs) == len(input_fields):
    input_data = np.array(user_inputs).reshape(1, 1, -1)  # Reshape as (batch_size, time_steps, features)

    # Get prediction from the model
    try:
        prediction = model.predict(input_data)
        predicted_class = np.argmax(prediction)
        predicted_label = label_mapping[predicted_class]
        depression_percentage = prediction[0][predicted_class] * 100
        print(f"Predicted Label: {predicted_label}, Depression Level: {depression_percentage:.2f}%")
    except Exception as e:
        print(f"Error during prediction: {e}")
else:
    print("Input process terminated due to invalid or incomplete data.")

# Save the input data and prediction results to a .txt file
if 'predicted_label' in locals() and 'depression_percentage' in locals():
    try:
        # Save user inputs and prediction result to a text file
        with open("depression_prediction_result.txt", "w") as file:
            file.write("User Inputs:\n")
            for field, value in zip(input_fields, user_inputs):
                file.write(f"{field}: {value}\n")

            file.write("\nPrediction Result:\n")
            file.write(f"Predicted Label: {predicted_label}\n")
            file.write(f"Depression Level: {depression_percentage:.2f}%\n")

        print("Prediction results saved to depression_prediction_result.txt")
    except Exception as e:
        print(f"Error saving result to file: {e}")
else:
    print("Prediction result not available, skipping file saving.")

import numpy as np
import tensorflow as tf
from fpdf import FPDF

# Function to gather user inputs
def gather_inputs():
    user_inputs = []

    input_mode = input("Would you like to input values one-by-one or all at once (enter 'one' or 'all')? ").strip().lower()

    if input_mode == 'all':
        print("Please enter the following values all in one line, separated by spaces or commas:")
        input_values = input("Enter values: ")

        # Split input by either commas or spaces
        for value in input_values.replace(',', ' ').split():  # Replace commas with spaces and split by spaces
            try:
                num_value = float(value)
                if num_value != 0:
                    user_inputs.append(num_value)
                else:
                    print("Zero is not allowed. Skipping this value.")
            except ValueError:
                print(f"Invalid input: {value}. Please ensure the input is a number.")

    elif input_mode == 'one':
        for field in input_fields:
            while True:
                value = input(f"Enter value for {field}: ")
                try:
                    validated_value = float(value)
                    if validated_value != 0:
                        user_inputs.append(validated_value)
                        break  # Move to the next input if validation is successful
                    else:
                        print("Zero is not allowed. Please enter a non-zero number.")
                except ValueError:
                    print(f"Invalid input: {value}. Please ensure the input is a number.")

    else:
        print("Invalid input mode. Please choose 'one' or 'all'.")

    return user_inputs

# Load the model
try:
    model = tf.keras.models.load_model('/content/my_model.keras')
    print("Model loaded successfully.")
except Exception as e:
    print(f"Error loading model: {e}")

# Define the label mapping for prediction
label_mapping = {0: "Negative", 1: "Neutral", 2: "Positive"}

# Input fields expected by the model (20 fields for user input)
input_fields = [
    "mean_0_a", "mean_1_a", "mean_2_a", "mean_3_a", "mean_4_a",
    "mean_d_0_a", "mean_d_1_a", "mean_d_2_a", "mean_d_3_a", "mean_d_4_a",
    "fft_741_b", "fft_742_b", "fft_743_b", "fft_744_b", "fft_745_b",
    "fft_746_b", "fft_747_b", "fft_748_b", "fft_749_b"
]

# Gather the user inputs
user_inputs = gather_inputs()

# Save the user inputs to a text file
if len(user_inputs) == len(input_fields):
    with open("user_input.txt", "w") as file:
        file.write("User Input Data:\n")
        for field, value in zip(input_fields, user_inputs):  # Corrected the typo
            file.write(f"{field}: {value}\n")
    print("User inputs saved to 'user_input.txt'.")

    # Create a padded input array with 2548 features (assuming padding with zeros)
    padded_inputs = np.zeros(2548)
    padded_inputs[:len(user_inputs)] = user_inputs  # Fill with user inputs, pad the rest with zeros

    # Print the shape of padded input data
    print(f"Padded input data shape: {padded_inputs.shape}")

    # Make a prediction using the model
    input_data = padded_inputs.reshape(1, -1)  # (batch_size, features)
    prediction = model.predict(input_data)
    predicted_label = label_mapping.get(int(prediction.argmax()), "Unknown")
    print(f"Predicted label: {predicted_label}")

    # Create PDF to display user inputs and the predicted label
    pdf = FPDF()
    pdf.set_auto_page_break(auto=True, margin=15)
    pdf.add_page()

    # Set font for the PDF
    pdf.set_font("Arial", size=12)

    # Add title
    pdf.cell(200, 10, txt="User Input and Prediction", ln=True, align='C')

    # Add user inputs to the PDF
    pdf.ln(10)  # Line break
    pdf.cell(200, 10, txt="User Inputs:", ln=True)
    for field, value in zip(input_fields, user_inputs):
        pdf.cell(200, 10, txt=f"{field}: {value}", ln=True)

    # Add the predicted label to the PDF
    pdf.ln(10)
    pdf.cell(200, 10, txt=f"Predicted Label: {predicted_label}", ln=True)

    # Save the PDF
    pdf.output("user_input_with_prediction.pdf")
    print("PDF saved as 'user_input_with_prediction.pdf'")

print(model.input_shape)

# prompt: model json file  saved

import json

# Sample data (replace with your actual data)
data = {
    "model_name": "my_model",
    "input_shape": [1, 2548],  # Assuming the input shape is [1, 2548]
    "label_mapping": {0: "Negative", 1: "Neutral", 2: "Positive"},
    "input_fields": [
        "mean_0_a", "mean_1_a", "mean_2_a", "mean_3_a", "mean_4_a",
        "mean_d_0_a", "mean_d_1_a", "mean_d_2_a", "mean_d_3_a", "mean_d_4_a",
        "fft_741_b", "fft_742_b", "fft_743_b", "fft_744_b", "fft_745_b",
        "fft_746_b", "fft_747_b", "fft_748_b", "fft_749_b"
    ]
}

# Save the data to a JSON file
with open("model_info.json", "w") as json_file:
    json.dump(data, json_file, indent=4)  # Use indent for pretty printing

print("Model information saved to model_info.json")

import numpy as np
import tensorflow as tf

# Load the model
try:
    model = tf.keras.models.load_model('/content/my_model.keras')
    print("Model loaded successfully.")
except Exception as e:
    print(f"Error loading model: {e}")

# Define the label mapping for prediction
label_mapping = {0: "Negative", 1: "Neutral", 2: "Positive"}

# Input fields expected by the model (20 fields for user input)
input_fields = [
    "mean_0_a", "mean_1_a", "mean_2_a", "mean_3_a", "mean_4_a",
    "mean_d_0_a", "mean_d_1_a", "mean_d_2_a", "mean_d_3_a", "mean_d_4_a",
    "fft_741_b", "fft_742_b", "fft_743_b", "fft_744_b", "fft_745_b",
    "fft_746_b", "fft_747_b", "fft_748_b", "fft_749_b"
]

# Prompt the user for input values
user_inputs = []
print("Please enter the following values (one by one):")

for field in input_fields:
    while True:
        try:
            # Accepting each input with the corresponding field name
            user_input = input(f"Enter value for {field}: ")
            user_inputs.append(float(user_input))  # Convert the input to a float
            break  # Exit the loop once a valid input is given
        except ValueError:
            print("Invalid input. Please enter a valid number.")

# Save the user inputs to a file
if len(user_inputs) == len(input_fields):
    with open("user_input.txt", "w") as file:
        file.write("User Input Data:\n")
        for field, value in zip(input_fields, user_inputs):  # Corrected the typo
            file.write(f"{field}: {value}\n")
    print("User inputs saved to 'user_input.txt'.")

    # Create a padded input array with 2548 features (assuming padding with zeros)
    padded_inputs = np.zeros(2548)
    padded_inputs[:len(user_inputs)] = user_inputs  # Fill with user inputs, pad the rest with zeros

    # Print the shape of padded input data
    print(f"Padded input data shape: {padded_inputs.shape}")

    # Make a prediction using the model
    input_data = padded_inputs.reshape(1, -1)  # (batch_size, features)
    prediction = model.predict(input_data)
    predicted_label = label_mapping.get(int(prediction.argmax()), "Unknown")
    print(f"Predicted label: {predicted_label}")